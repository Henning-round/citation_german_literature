{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05fdf348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manager import load_obj, save_obj\n",
    "from Homework import Homework\n",
    "from pprint import pprint\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e24ab",
   "metadata": {},
   "source": [
    "# Chosing bibliography for goldstandard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "166fde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    txt = re.sub(r\"[^a-z0-9äöü]\", \"\", txt.lower())\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8715ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(txt):\n",
    "    txt = re.sub(r\"[^a-zäöü]\", \"\", txt.lower())\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d1802635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_edit(txt):\n",
    "    txt = re.sub(r\"(\\s*in\\:|hsg\\..{1}v|hrsg\\.|hsg\\.|hsgg\\.|hg.|\\s*v\\.)\", \"\", txt.lower())\n",
    "    txt = re.sub(r\"[^a-z0-9äöü]\", \"\", txt.lower())\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ccb89efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"author\", \"title\", \"publisher\", \"location\", \"editor\", \"source\", \"date\", \"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "95f8e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit for the confusion matrix: https://www.educative.io/edpresso/how-to-create-a-confusion-matrix-without-scikit-learn\n",
    "def confusion_matrix(pred,original): #pass predicted and original labels to this function\n",
    "    matrix=np.zeros((2,2)) # form an empty matric of 2x2\n",
    "    \n",
    "    for val_p,val_o in zip(pred,original): #the confusion matrix is for 2 classes: 1,0\n",
    "        \n",
    "        if (val_o != \"\") and (val_o == val_p):\n",
    "            matrix[0,0]+=1 #True Positives\n",
    "        elif (val_o == \"\") and (val_o != val_p):\n",
    "            matrix[0,1]+=1 #False Positives\n",
    "        elif (val_o != \"\") and (val_o != val_p):\n",
    "            matrix[1,0]+=1 #False Negatives\n",
    "        elif (val_o == \"\") and (val_p ==\"\"):\n",
    "            matrix[1,1]+=1 #True Negatives\n",
    "    precision=matrix[0,0]/(matrix[0,0]+matrix[0,1])\n",
    "    print(\"Precision:\",precision)\n",
    "    recall=matrix[0,0]/(matrix[0,0]+matrix[1,0])\n",
    "    print(\"Recall:\",recall)\n",
    "    f1=2 * ((precision*recall)/(precision+recall))\n",
    "    print(\"F1 score:\",f1)\n",
    "    print(matrix)\n",
    "\n",
    "    #the above code adds up the frequencies of the tps,tns,fps,fns and a matrix is formed\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f26a10",
   "metadata": {},
   "source": [
    "## 1.Anystyle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1e2cfd3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for val in ground_truth:\n",
    "    for ref in val:\n",
    "        if ref.find(\"journal\"):\n",
    "            print(clean_edit(ref.find(\"journal\").text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e44b3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ground_truth =[]\n",
    "path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"ground_truth\")\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), 'r', encoding=\"utf8\") as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        data = BeautifulSoup(data, 'xml') \n",
    "        data = data.find_all(\"sequence\")\n",
    "        ground_truth.append(data)\n",
    "        \n",
    "anystyle =[]\n",
    "path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"anystyle\")\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), 'r', encoding=\"utf8\") as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        data = BeautifulSoup(data, 'xml') \n",
    "        data = data.find_all(\"sequence\")\n",
    "        anystyle.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e22a9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    if len(anystyle[i]) != len(ground_truth[i]):\n",
    "        print(\"error\" + str(i))\n",
    "        print(anystyle[i])\n",
    "        print(\"\\n\\n\")\n",
    "        print(ground_truth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "90f13d94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "\n",
      "Precision: 0.8947368421052632\n",
      "Recall: 0.7251184834123223\n",
      "F1 score: 0.8010471204188482\n",
      "[[153.  18.]\n",
      " [ 58.  29.]]\n",
      "\n",
      "\n",
      "title\n",
      "\n",
      "Precision: 0.9\n",
      "Recall: 0.5294117647058824\n",
      "F1 score: 0.6666666666666667\n",
      "[[117.  13.]\n",
      " [104.  24.]]\n",
      "\n",
      "\n",
      "publisher\n",
      "\n",
      "Precision: 0.7888888888888889\n",
      "Recall: 0.8068181818181818\n",
      "F1 score: 0.797752808988764\n",
      "[[ 71.  19.]\n",
      " [ 17. 151.]]\n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "Precision: 0.9487179487179487\n",
      "Recall: 0.6568047337278107\n",
      "F1 score: 0.7762237762237761\n",
      "[[111.   6.]\n",
      " [ 58.  83.]]\n",
      "\n",
      "\n",
      "editor\n",
      "\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.603448275862069\n",
      "F1 score: 0.7446808510638298\n",
      "[[ 35.   1.]\n",
      " [ 23. 199.]]\n",
      "\n",
      "\n",
      "source\n",
      "\n",
      "Precision: 0.7733333333333333\n",
      "Recall: 0.5420560747663551\n",
      "F1 score: 0.6373626373626373\n",
      "[[ 58.  17.]\n",
      " [ 49. 134.]]\n",
      "\n",
      "\n",
      "date\n",
      "\n",
      "Precision: 0.9946808510638298\n",
      "Recall: 0.8348214285714286\n",
      "F1 score: 0.9077669902912622\n",
      "[[187.   1.]\n",
      " [ 37.  33.]]\n",
      "\n",
      "\n",
      "url\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.6\n",
      "F1 score: 0.7499999999999999\n",
      "[[  3.   0.]\n",
      " [  2. 253.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "for label in labels:\n",
    "    lab_any =[]\n",
    "    lab_ground =[]\n",
    "    for val_any, val_ground in zip(anystyle, ground_truth):\n",
    "        for label_any, label_ground in zip(val_any,val_ground):\n",
    "            tag_a = label_any.find_all(label)\n",
    "            tag_g = label_ground.find_all(label)\n",
    "            if tag_a:\n",
    "                if label == \"editor\" or label == \"source\":\n",
    "                    lab_any.append(clean_edit(\"\".join([word.text for word in tag_a])))\n",
    "                elif label == \"location\" or label == \"publisher\" or label == \"author\":\n",
    "                    lab_any.append(clean_location(\"\".join([word.text for word in tag_a])))\n",
    "                else:\n",
    "                    lab_any.append(clean(\"\".join([word.text for word in tag_a])))\n",
    "            else:\n",
    "                lab_any.append(\"\")\n",
    "            if tag_g:\n",
    "                if label == \"editor\" or label == \"source\":\n",
    "                    lab_ground.append(clean_edit(\"\".join([word.text for word in tag_g])))\n",
    "                elif label == \"location\" or label == \"publisher\" or label == \"author\":\n",
    "                    lab_ground.append(clean_location(\"\".join([word.text for word in tag_g])))\n",
    "                else:\n",
    "                    lab_ground.append(clean(\"\".join([word.text for word in tag_g])))\n",
    "            else:\n",
    "                lab_ground.append(\"\")\n",
    "                \n",
    "    \"\"\"\n",
    "    for i,j in zip(lab_any, lab_ground):\n",
    "        print(\"any \" + i)\n",
    "        print(\"gro \" + j)\n",
    "    \"\"\"\n",
    "    print(label+ \"\\n\")\n",
    "    confusion_matrix(lab_any,lab_ground)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d73c15",
   "metadata": {},
   "source": [
    "## 2. Grobid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3251348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ground_truth =[]\n",
    "path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"ground_truth\")\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), 'r', encoding=\"utf8\") as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        data = BeautifulSoup(data, 'xml') \n",
    "        data = data.find_all(\"sequence\")\n",
    "        ground_truth.append(data)\n",
    "        \n",
    "grobid =[]\n",
    "path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"grobid_xml\")\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), 'r', encoding=\"utf8\") as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        data = BeautifulSoup(data, 'xml') \n",
    "        data = data.find_all(\"sequence\")\n",
    "        grobid.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2028e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    if len(grobid[i]) != len(ground_truth[i]):\n",
    "        print(\"error\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "404c7333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "\n",
      "Precision: 0.844559585492228\n",
      "Recall: 0.7725118483412322\n",
      "F1 score: 0.8069306930693069\n",
      "[[163.  30.]\n",
      " [ 48.  17.]]\n",
      "\n",
      "\n",
      "title\n",
      "\n",
      "Precision: 0.8796296296296297\n",
      "Recall: 0.4298642533936652\n",
      "F1 score: 0.5775075987841946\n",
      "[[ 95.  13.]\n",
      " [126.  24.]]\n",
      "\n",
      "\n",
      "publisher\n",
      "\n",
      "Precision: 0.8723404255319149\n",
      "Recall: 0.4659090909090909\n",
      "F1 score: 0.6074074074074074\n",
      "[[ 41.   6.]\n",
      " [ 47. 164.]]\n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.2781065088757396\n",
      "F1 score: 0.4351851851851852\n",
      "[[ 47.   0.]\n",
      " [122.  89.]]\n",
      "\n",
      "\n",
      "editor\n",
      "\n",
      "Precision: 0.8484848484848485\n",
      "Recall: 0.4827586206896552\n",
      "F1 score: 0.6153846153846154\n",
      "[[ 28.   5.]\n",
      " [ 30. 195.]]\n",
      "\n",
      "\n",
      "source\n",
      "\n",
      "Precision: 0.7551020408163265\n",
      "Recall: 0.34579439252336447\n",
      "F1 score: 0.47435897435897434\n",
      "[[ 37.  12.]\n",
      " [ 70. 139.]]\n",
      "\n",
      "\n",
      "date\n",
      "\n",
      "Precision: 0.9951923076923077\n",
      "Recall: 0.9241071428571429\n",
      "F1 score: 0.9583333333333334\n",
      "[[207.   1.]\n",
      " [ 17.  33.]]\n",
      "\n",
      "\n",
      "url\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.8\n",
      "F1 score: 0.888888888888889\n",
      "[[  4.   0.]\n",
      " [  1. 253.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "for label in labels:\n",
    "    lab_grobid =[]\n",
    "    lab_ground =[]\n",
    "    for val_grobid, val_ground in zip(grobid, ground_truth):\n",
    "        for label_grobid, label_ground in zip(val_grobid,val_ground):\n",
    "            tag_grob = label_grobid.find_all(label)\n",
    "            tag_g = label_ground.find_all(label)\n",
    "            \n",
    "            for i in range(len(tag_grob)):\n",
    "                if tag_grob[i].text == \"\":\n",
    "                    tag_grob.remove(tag_grob[i]) \n",
    "            \n",
    "            \n",
    "            \n",
    "            if tag_grob != \"\":\n",
    "                if label == \"editor\" or label == \"source\":\n",
    "                    lab_grobid.append(clean_edit(\"\".join([word.text for word in tag_grob])))\n",
    "                elif label == \"location\" or label == \"publisher\" or label == \"author\":\n",
    "                    lab_grobid.append(clean_location(\"\".join([word.text for word in tag_grob])))\n",
    "                else:\n",
    "                    lab_grobid.append(clean(\"\".join([word.text for word in tag_grob])))\n",
    "            else:\n",
    "                lab_grobid.append(\"\")\n",
    "            if tag_g:\n",
    "                if label == \"editor\" or label == \"source\":\n",
    "                    lab_ground.append(clean_edit(\"\".join([word.text for word in tag_g])))\n",
    "                elif label == \"location\" or label == \"publisher\" or label == \"author\":\n",
    "                    lab_ground.append(clean_location(\"\".join([word.text for word in tag_g])))\n",
    "                else:\n",
    "                    lab_ground.append(clean(\"\".join([word.text for word in tag_g])))\n",
    "            else:\n",
    "                lab_ground.append(\"\")\n",
    "    \n",
    "    \"\"\"\n",
    "    for i,j in zip(lab_grobid, lab_ground):\n",
    "        print(\"any \" + i)\n",
    "        print(\"gro \" + j)\n",
    "    \"\"\"\n",
    "\n",
    "    print(label+ \"\\n\")\n",
    "    confusion_matrix(lab_grobid,lab_ground)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bec6f",
   "metadata": {},
   "source": [
    "## 3. Exparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6710a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =[]\n",
    "#path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"ground_truth\")\n",
    "path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"ground_truth\")\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), 'r', encoding=\"utf8\") as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        data = BeautifulSoup(data, \"xml\") \n",
    "        data = data.find_all(\"sequence\")\n",
    "        ground_truth.append(data)\n",
    "\n",
    "exparser =[]\n",
    "path = os.path.join(\"C:\\\\\", \"Users\", \"Tim\", \"Desktop\", \"bachelorarbeit\", \"goldstandards\",\"exparser_xml\")\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), 'r', encoding=\"utf8\") as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        data = BeautifulSoup(data, \"xml\") \n",
    "        data = data.find_all(\"sequence\")\n",
    "        exparser.append(data)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e4b6af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    if len(exparser[i]) != len(ground_truth[i]):\n",
    "        print(\"error\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "276a1c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "\n",
      "Precision: 0.8938547486033519\n",
      "Recall: 0.7582938388625592\n",
      "F1 score: 0.8205128205128205\n",
      "[[160.  19.]\n",
      " [ 51.  28.]]\n",
      "\n",
      "\n",
      "title\n",
      "\n",
      "Precision: 0.9493670886075949\n",
      "Recall: 0.6787330316742082\n",
      "F1 score: 0.79155672823219\n",
      "[[150.   8.]\n",
      " [ 71.  29.]]\n",
      "\n",
      "\n",
      "publisher\n",
      "\n",
      "Precision: 0.9661016949152542\n",
      "Recall: 0.6477272727272727\n",
      "F1 score: 0.7755102040816327\n",
      "[[ 57.   2.]\n",
      " [ 31. 168.]]\n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "Precision: 0.8451612903225807\n",
      "Recall: 0.7751479289940828\n",
      "F1 score: 0.808641975308642\n",
      "[[131.  24.]\n",
      " [ 38.  65.]]\n",
      "\n",
      "\n",
      "editor\n",
      "\n",
      "Precision: 0.65\n",
      "Recall: 0.6724137931034483\n",
      "F1 score: 0.6610169491525424\n",
      "[[ 39.  21.]\n",
      " [ 19. 179.]]\n",
      "\n",
      "\n",
      "source\n",
      "\n",
      "Precision: 0.8734177215189873\n",
      "Recall: 0.6448598130841121\n",
      "F1 score: 0.7419354838709676\n",
      "[[ 69.  10.]\n",
      " [ 38. 141.]]\n",
      "\n",
      "\n",
      "date\n",
      "\n",
      "Precision: 0.9952380952380953\n",
      "Recall: 0.9330357142857143\n",
      "F1 score: 0.9631336405529954\n",
      "[[209.   1.]\n",
      " [ 15.  33.]]\n",
      "\n",
      "\n",
      "url\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.6\n",
      "F1 score: 0.7499999999999999\n",
      "[[  3.   0.]\n",
      " [  2. 253.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "for label in labels:\n",
    "    lab_exparser =[]\n",
    "    lab_ground =[]\n",
    "    for val_exparser, val_ground in zip(exparser, ground_truth):\n",
    "        for label_exparser, label_ground in zip(val_exparser,val_ground):\n",
    "            tag_exp = label_exparser.find_all(label)\n",
    "            tag_g = label_ground.find_all(label)\n",
    "            \n",
    "            \n",
    "            for i in range(len(tag_exp)):\n",
    "                if tag_exp[i].text == \"\":\n",
    "                    tag_exp.remove(tag_exp[i]) \n",
    "            \n",
    "            if len(tag_exp) != 0:\n",
    "                if label == \"editor\" or label == \"source\":\n",
    "                    lab_exparser.append(clean_edit(\"\".join([word.text for word in tag_exp])))\n",
    "                elif label == \"location\" or label == \"publisher\" or label == \"author\":\n",
    "                    lab_exparser.append(clean_location(\"\".join([word.text for word in tag_exp])))\n",
    "                else:\n",
    "                    lab_exparser.append(clean(\"\".join([word.text for word in tag_exp])))\n",
    "            else:\n",
    "                lab_exparser.append(\"\")\n",
    "            \n",
    "            if len(tag_g) != 0:\n",
    "                if label == \"editor\" or label == \"source\":\n",
    "                    lab_ground.append(clean_edit(\"\".join([word.text for word in tag_g])))\n",
    "                elif label == \"location\" or label == \"publisher\" or label == \"author\":\n",
    "                    lab_ground.append(clean_location(\"\".join([word.text for word in tag_g])))\n",
    "                else:\n",
    "                    lab_ground.append(clean(\"\".join([word.text for word in tag_g])))\n",
    "            else:\n",
    "                lab_ground.append(\"\")\n",
    "\n",
    "    \"\"\"\n",
    "    for i,j in zip(lab_exparser, lab_ground):\n",
    "        print(\"any \" + i)\n",
    "        print(\"gro \" + j)\n",
    "    \"\"\"\n",
    "    print(label+ \"\\n\")\n",
    "    confusion_matrix(lab_exparser,lab_ground)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bachelor] *",
   "language": "python",
   "name": "conda-env-bachelor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
